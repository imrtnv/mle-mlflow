{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, recall_score, \n",
    "    log_loss, confusion_matrix, mean_squared_error, r2_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "# Загрузка переменных из файла .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем основные credentials, которые нужны для подключения к MLflow\n",
    "# важно, что credentials мы передаём для себя как пользователей Tracking Service\n",
    "# у вас должен быть доступ к бакету, в который вы будете складывать артефакты\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "dst_host = os.environ.get('DB_DESTINATION_HOST')\n",
    "dst_port = os.environ.get('DB_DESTINATION_PORT')\n",
    "dst_username = os.environ.get('DB_DESTINATION_USER')\n",
    "dst_password = os.environ.get('DB_DESTINATION_PASSWORD')\n",
    "dst_db = os.environ.get('DB_DESTINATION_NAME')\n",
    "\n",
    "src_host = os.environ.get('DB_SOURCE_HOST')\n",
    "src_port = os.environ.get('DB_SOURCE_PORT')\n",
    "src_username = os.environ.get('DB_SOURCE_USER')\n",
    "src_password = os.environ.get('DB_SOURCE_PASSWORD')\n",
    "src_db = os.environ.get('DB_SOURCE_NAME') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройки эксперимента\n",
    "YOUR_NAME = \"imartnv\" # введите своё имя для создания уникального эксперимента\n",
    "assert YOUR_NAME, \"введите своё имя в переменной YOUR_NAME для создания уникального эксперимента\"\n",
    "\n",
    "# название тестового эксперимента и запуска (run) внутри него\n",
    "EXPERIMENT_NAME = f\"churn_experiment_{YOUR_NAME}\"\n",
    "RUN_NAME = \"model_0_registry\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_martynov_alexey\"\n",
    "\n",
    "\n",
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "# устанавливаем host, который будет отслеживать наши эксперименты\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим соединения\n",
    "src_conn = create_engine(f'postgresql://{src_username}:{src_password}@{src_host}:{src_port}/{src_db}')\n",
    "dst_conn = create_engine(f'postgresql://{dst_username}:{dst_password}@{dst_host}:{dst_port}/{dst_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример выгрузки данных из БД\n",
    "TABLE = 'alt_users_churn'\n",
    "SQL = f'select * from {TABLE}'\n",
    "data = pd.read_sql(SQL, dst_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция удаления дубликатов\n",
    "def remove_duplicates(data):\n",
    "    feature_cols = data.columns.drop('customer_id').tolist()\n",
    "    is_duplicated_features = data.duplicated(subset=feature_cols, keep=False)\n",
    "    data = data[~is_duplicated_features].reset_index(drop=True)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция для заполнения пропусков\n",
    "def fill_missing_values(data):\n",
    "    cols_with_nans = data.isnull().sum()\n",
    "    cols_with_nans = cols_with_nans[cols_with_nans > 0].index.drop('end_date')\n",
    "    for col in cols_with_nans:\n",
    "        if data[col].dtype in [float, int]:\n",
    "            fill_value = data[col].mean()\n",
    "        elif data[col].dtype == 'object':\n",
    "            fill_value = data[col].mode().iloc[0]\n",
    "        data[col] = data[col].fillna(fill_value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция удаления выбросов\n",
    "def remove_outliers(df: pd.DataFrame, threshold: float = 1.5) -> pd.DataFrame:\n",
    "        num_cols = df.select_dtypes(include=['float']).columns\n",
    "        potential_outliers = pd.DataFrame(False, index=df.index, columns=num_cols)\n",
    "        \n",
    "        for col in num_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            margin = threshold * IQR\n",
    "            lower = Q1 - margin\n",
    "            upper = Q3 + margin\n",
    "            potential_outliers[col] = ~df[col].between(lower, upper)\n",
    "        \n",
    "        outliers = potential_outliers.any(axis=1)\n",
    "        df_cleaned = df[~outliers]\n",
    "        return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Почистим датасет\n",
    "data = fill_missing_values(data)\n",
    "data = remove_duplicates(data)\n",
    "data = remove_outliers(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('id')\n",
    "data = data.drop(columns=['customer_id','begin_date','end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-mlflow/.venv_mle_mlflow/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Разделение признаков на числовые и категориальные\n",
    "num_features = data.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "cat_features = data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Преобразование числовых признаков\n",
    "scaler = StandardScaler()\n",
    "num_features_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(data[num_features]),\n",
    "    columns=num_features,\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "# Преобразование категориальных признаков в One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "cat_features_encoded = pd.DataFrame(\n",
    "    encoder.fit_transform(data[cat_features]),\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "# 2. Объединение преобразованных признаков\n",
    "transformed_data = pd.concat([num_features_scaled, cat_features_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f77ac08fca0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение модели CatBoostClassifier\n",
    "X = transformed_data.drop(columns='target')\n",
    "y = data['target']  # Целевая переменная\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100, \n",
    "    depth=4, \n",
    "    learning_rate=0.1, \n",
    "    loss_function='Logloss', \n",
    "    verbose=0\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания\n",
    "y_pred = model.predict(X_test)  # Бинарные предсказания\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Вероятности положительного класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_proba)\n",
    "\n",
    "# Матрица ошибок с нормализацией\n",
    "conf_matrix_normalized = confusion_matrix(y_test, y_pred, normalize='all')\n",
    "\n",
    "# Ошибки первого и второго рода\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "err_1 = fp / (fp + tn)  # Ошибка первого рода\n",
    "err_2 = fn / (fn + tp)  # Ошибка второго рода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.85\n",
      "F1-мера: 0.58\n",
      "Precision (точность): 0.71\n",
      "Recall (полнота): 0.49\n",
      "Log-loss: 0.42\n",
      "Confusion Matrix (normalized):\n",
      "[[0.66430092 0.05606813]\n",
      " [0.14194464 0.1376863 ]]\n",
      "Ошибка первого рода (err_1): 0.08\n",
      "Ошибка второго рода (err_2): 0.51\n"
     ]
    }
   ],
   "source": [
    "# 11. Вывод метрик\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "print(f\"F1-мера: {f1:.2f}\")\n",
    "print(f\"Precision (точность): {precision:.2f}\")\n",
    "print(f\"Recall (полнота): {recall:.2f}\")\n",
    "print(f\"Log-loss: {logloss:.2f}\")\n",
    "print(\"Confusion Matrix (normalized):\")\n",
    "print(conf_matrix_normalized)\n",
    "print(f\"Ошибка первого рода (err_1): {err_1:.2f}\")\n",
    "print(f\"Ошибка второго рода (err_2): {err_2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройки логирования модели\n",
    "# ------------------------------------------------------------------\n",
    "pip_requirements = \"/home/mle-user/mle_projects/mle-mlflow/requirements.txt\"\n",
    "signature = mlflow.models.infer_signature(X_test, y_pred)\n",
    "input_example = X_test[:10]\n",
    "metadata = {'model_type': 'monthly'}\n",
    "\n",
    "# Получим ID эксперимента\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'churn_model_martynov_alexey' already exists. Creating a new version of this model...\n",
      "2025/01/14 15:39:28 INFO mlflow.tracking._model_registry.client: Waiting up to 60 seconds for model version to finish creation. Model name: churn_model_martynov_alexey, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 786659fe583746f090328c8e3e207bfd\n",
      "Model logged to MLflow with ID: runs:/786659fe583746f090328c8e3e207bfd/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'churn_model_martynov_alexey'.\n"
     ]
    }
   ],
   "source": [
    "# Логирование в MLflow\n",
    "# ------------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Логируем гиперпараметры модели\n",
    "    mlflow.log_param(\"iterations\", 100)\n",
    "    mlflow.log_param(\"depth\", 4)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"loss_function\", \"Logloss\")\n",
    "    \n",
    "    # Логируем метрики\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"log_loss\", logloss)\n",
    "    mlflow.log_metric(\"error_type_1\", err_1)\n",
    "    mlflow.log_metric(\"error_type_2\", err_2)\n",
    "\n",
    "    # Пример: логируем матрицу ошибок как артефакт (картинку)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(conf_matrix_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.savefig(\"conf_matrix.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"conf_matrix.png\")\n",
    "\n",
    "    # Логируем модель (CatBoost) вместе с окружением\n",
    "    model_info = mlflow.catboost.log_model(\n",
    "        cb_model=model,\n",
    "        artifact_path=\"models\",\n",
    "        registered_model_name=REGISTRY_MODEL_NAME,\n",
    "        input_example=input_example,\n",
    "        metadata=metadata,\n",
    "        signature=signature,\n",
    "        pip_requirements=pip_requirements,\n",
    "        await_registration_for=60  # время ожидания регистрации в Model Registry\n",
    "    )\n",
    "\n",
    "print(\"Run ID:\", run_id)\n",
    "print(\"Model logged to MLflow with ID:\", model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = f\"models:/{REGISTRY_MODEL_NAME}/1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3151fdb86e2c4fda9c8d7aaf071d1fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузка модели из реестра\n",
    "loaded_model = mlflow.catboost.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.MlflowClient()\n",
    "\n",
    "REGISTRY_MODEL_NAME = 'churn_model_nikolaistepanov'\n",
    "\n",
    "models = client.search_model_versions(filter_string=f\"name = '{REGISTRY_MODEL_NAME}'\")\n",
    "print(f\"Model info:\\n {models}\")\n",
    "\n",
    "model_name_1 = models[-1].name\n",
    "model_version_1 = models[-1].version\n",
    "model_stage_1 = models[-1].current_stage\n",
    "\n",
    "model_name_2 = models[-2].name\n",
    "model_version_2 = models[-2].version\n",
    "model_stage_2 = models[-2].current_stage\n",
    "\n",
    "\n",
    "print(f\"Текущий stage модели 1: {model_stage_1}\")\n",
    "print(f\"Текущий stage модели 2: {model_stage_2}\")\n",
    "\n",
    "# поменяйте статус каждой модели\n",
    "client.transition_model_version_stage(model_name_1, model_version_1, 'production')\n",
    "client.transition_model_version_stage(model_name_2, model_version_2, 'staging')\n",
    "\n",
    "# переимнуйте модель в реестре\n",
    "client.rename_registered_model(name=REGISTRY_MODEL_NAME, new_name=f'{REGISTRY_MODEL_NAME}_b2c')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('.venv_mle_mlflow': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d3d420c415bb1e4ded8deb074a36e773da5522490881136d2c56750521659c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
