{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    SplineTransformer, \n",
    "    QuantileTransformer, \n",
    "    RobustScaler,\n",
    "    PolynomialFeatures,\n",
    "    KBinsDiscretizer,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, recall_score, \n",
    "    log_loss, confusion_matrix, mean_squared_error, r2_score\n",
    ")\n",
    "from catboost import CatBoostClassifier\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import psycopg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаем .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_NAME = \"alt_users_churn\" # таблица с данными в postgres \n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "\n",
    "# Параметры для трекинга эксперимента\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_experiment_imartnv\"\n",
    "RUN_NAME = \"preprocessing\" \n",
    "REGISTRY_MODEL_NAME = \"churn_model_martynov_alexey\"\n",
    "\n",
    "# Настрофка отображения\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 64\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_theme(style=\"whitegrid\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение к базе и получение данных\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция удаления дубликатов\n",
    "def remove_duplicates(data):\n",
    "    feature_cols = data.columns.drop('customer_id').tolist()\n",
    "    is_duplicated_features = data.duplicated(subset=feature_cols, keep=False)\n",
    "    data = data[~is_duplicated_features].reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция для заполнения пропусков\n",
    "def fill_missing_values(data):\n",
    "    cols_with_nans = data.isnull().sum()\n",
    "    cols_with_nans = cols_with_nans[cols_with_nans > 0].index.drop('end_date')\n",
    "    for col in cols_with_nans:\n",
    "        if data[col].dtype in [float, int]:\n",
    "            fill_value = data[col].mean()\n",
    "        elif data[col].dtype == 'object':\n",
    "            fill_value = data[col].mode().iloc[0]\n",
    "        data[col] = data[col].fillna(fill_value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция удаления выбросов\n",
    "def remove_outliers(df: pd.DataFrame, threshold: float = 1.5) -> pd.DataFrame:\n",
    "        num_cols = df.select_dtypes(include=['float']).columns\n",
    "        potential_outliers = pd.DataFrame(False, index=df.index, columns=num_cols)\n",
    "        \n",
    "        for col in num_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            margin = threshold * IQR\n",
    "            lower = Q1 - margin\n",
    "            upper = Q3 + margin\n",
    "            potential_outliers[col] = ~df[col].between(lower, upper)\n",
    "        \n",
    "        outliers = potential_outliers.any(axis=1)\n",
    "        df_cleaned = df[~outliers]\n",
    "        return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Почистим датасет\n",
    "df = fill_missing_values(df)\n",
    "df = remove_duplicates(df)\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('id')\n",
    "df = df.drop(columns=['customer_id','begin_date','end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df = df.select_dtypes(include=\"object\")\n",
    "cat_columns = [\"type\", \"payment_method\", \"internet_service\", \"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include='float64').dropna()\n",
    "num_columns = [\"monthly_charges\", \"total_charges\"]\n",
    "\n",
    "n_knots = 3\n",
    "degree_spline = 4\n",
    "n_quantiles=100\n",
    "degree = 3\n",
    "n_bins = 5\n",
    "encode = 'ordinal'\n",
    "strategy = 'uniform'\n",
    "subsample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['monthly_charges','total_charges'],inplace=True)\n",
    "num_df = df[num_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = [\"monthly_charges\", \"total_charges\"]\n",
    "\n",
    "n_knots = 3\n",
    "degree_spline = 4\n",
    "n_quantiles=100\n",
    "degree = 3\n",
    "n_bins = 5\n",
    "encode = 'ordinal'\n",
    "strategy = 'uniform'\n",
    "subsample = None\n",
    "\n",
    "\n",
    "# SplineTransformer\n",
    "encoder_spl = SplineTransformer(n_knots=n_knots, degree=degree_spline)\n",
    "encoded_features = encoder_spl.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_spl.get_feature_names_out(num_columns))\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# QuantileTransformer\n",
    "encoder_q = QuantileTransformer(n_quantiles=n_quantiles)\n",
    "encoded_features = encoder_q.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_q.get_feature_names_out(num_columns))\n",
    "\n",
    "encoded_df.columns = [col + f\"_q_{n_quantiles}\" for col in num_columns]\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# RobustScaler\n",
    "encoder_rb = RobustScaler()\n",
    "encoded_features = encoder_rb.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_rb.get_feature_names_out(num_columns))\n",
    "encoded_df.columns = [col + f\"_robust\" for col in num_columns]\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# PolynomialFeatures\n",
    "encoder_pol = PolynomialFeatures(degree=degree)\n",
    "encoded_features = encoder_pol.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_pol.get_feature_names_out(num_columns))\n",
    "encoded_df.drop(encoded_df.columns[:1 + len(num_columns)], axis=1, inplace=True)\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "# KBinsDiscretizer\n",
    "encoder_kbd = KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy, subsample=subsample)\n",
    "encoded_features = encoder_kbd.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_kbd.get_feature_names_out(num_columns))\n",
    "\n",
    "encoded_df.columns = [col + f\"_bin\" for col in num_columns]\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "num_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('spline', SplineTransformer(n_knots=n_knots, degree=degree_spline), num_columns),\n",
    "        ('quantile', QuantileTransformer(n_quantiles=n_quantiles), num_columns),\n",
    "        ('robust', RobustScaler(), num_columns),\n",
    "        ('polynomial', PolynomialFeatures(degree=degree), num_columns),\n",
    "        ('kbins', KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy, subsample=subsample), num_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "\tsteps=[\n",
    "        ('onehot',OneHotEncoder(categories='auto', handle_unknown='ignore', max_categories=10, sparse_output=False, drop='first'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "\t('num',numeric_transformer,num_columns),\n",
    "    ('cat',categorical_transformer,cat_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "encoded_features = preprocessor.fit_transform(df)\n",
    "\n",
    "transformed_df = pd.DataFrame(encoded_features, columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "df = pd.concat([df.reset_index(drop=True), transformed_df.reset_index(drop=True)], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "#mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "#experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "#with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "#    run_id = run.info.run_id\n",
    "\n",
    "#    mlflow.sklearn.log_model(preprocessor, \"column_transformer\") \n",
    "    \n",
    "#    print(f\"Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели CatBoostClassifier\n",
    "X = transformed_df\n",
    "y = df['target']  # Целевая переменная\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100, \n",
    "    depth=4, \n",
    "    learning_rate=0.1, \n",
    "    loss_function='Logloss', \n",
    "    verbose=0\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания\n",
    "y_pred = model.predict(X_test)  # Бинарные предсказания\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Вероятности положительного класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_proba)\n",
    "\n",
    "# Матрица ошибок с нормализацией\n",
    "conf_matrix_normalized = confusion_matrix(y_test, y_pred, normalize='all')\n",
    "\n",
    "# Ошибки первого и второго рода\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "err_1 = fp / (fp + tn)  # Ошибка первого рода\n",
    "err_2 = fn / (fn + tp)  # Ошибка второго рода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поднимаем MLflow локально\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "# устанавливаем host, который будет отслеживать наши эксперименты\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройки логирования модели\n",
    "# ------------------------------------------------------------------\n",
    "pip_requirements = \"/home/mle-user/mle_projects/mle-mlflow/requirements.txt\"\n",
    "signature = mlflow.models.infer_signature(X_test, y_pred)\n",
    "input_example = X_test[:10]\n",
    "metadata = {'model_type': 'monthly'}\n",
    "\n",
    "# Получим ID эксперимента\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "RUN_NAME = \"model_6_registry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Логирование в MLflow\n",
    "# ------------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Логируем гиперпараметры модели\n",
    "    mlflow.log_param(\"iterations\", 100)\n",
    "    mlflow.log_param(\"depth\", 4)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"loss_function\", \"Logloss\")\n",
    "    \n",
    "    # Логируем метрики\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"log_loss\", logloss)\n",
    "    mlflow.log_metric(\"error_type_1\", err_1)\n",
    "    mlflow.log_metric(\"error_type_2\", err_2)\n",
    "\n",
    "    # Пример: логируем матрицу ошибок как артефакт (картинку)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(conf_matrix_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.savefig(\"conf_matrix.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"conf_matrix.png\")\n",
    "\n",
    "    # Логируем модель (CatBoost) вместе с окружением\n",
    "    model_info = mlflow.catboost.log_model(\n",
    "        cb_model=model,\n",
    "        artifact_path=\"models\",\n",
    "        registered_model_name=REGISTRY_MODEL_NAME,\n",
    "        input_example=input_example,\n",
    "        metadata=metadata,\n",
    "        signature=signature,\n",
    "        pip_requirements=pip_requirements,\n",
    "        await_registration_for=60  # время ожидания регистрации в Model Registry\n",
    "    )\n",
    "\n",
    "print(\"Run ID:\", run_id)\n",
    "print(\"Model logged to MLflow with ID:\", model_info.model_uri)\n",
    "print(f\"✅ Model registered successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('.venv_mle_mlflow': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d3d420c415bb1e4ded8deb074a36e773da5522490881136d2c56750521659c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
